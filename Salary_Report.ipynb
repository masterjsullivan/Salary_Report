{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm6M_wfbi92b",
        "outputId": "7c2f56c0-7f51-4ff5-aab8-12400b54f4fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "!cd /content/drive/Shareddrives/'Replicon Data Source'/'Data Sources'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Allows access to google drive\n",
        "\n",
        "# Import Google libraries\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.auth import default\n",
        "\n",
        "# Authenticate and create a client\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Open the Google Sheets file\n",
        "spreadsheet = gc.open(\"Salary Activity Report\").sheet1\n",
        "\n",
        "# 'worksheet' object, fetching the data\n",
        "data = spreadsheet.get_all_values()"
      ],
      "metadata": {
        "id": "S-anJWgTjgV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Put that data into a Pandas dataframe\n",
        "df = pd.DataFrame(data)\n",
        "df.columns = df.iloc[0]\n",
        "df = df[1:]"
      ],
      "metadata": {
        "id": "2aF36NPem_tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a boolean list variable \"key\" where df records are null\n",
        "columns_to_check = ['VES DBQ + IMO total', 'LS DBQ + IMO total', 'QTC DBQ + IMO Total', 'Optum DBQ + IMO total', 'RHRP Eval total']\n",
        "df['activity_sums'] = df[columns_to_check].sum(axis=1)\n",
        "df['activity_sums'] = pd.to_numeric(df['activity_sums'], errors='coerce')\n",
        "df['activity_sums'] = df['activity_sums'].fillna(0)\n",
        "\n",
        "df['Hours'] = pd.to_numeric(df['Hours'], errors='coerce')\n",
        "df['Hours'] = df['Hours'].fillna(0)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dDwpoDgKZEJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#key = df [\"Activity Name\"].isnull()\n",
        "hours_key = (df[\"Hours\"] > 0)\n",
        "activity_key = df['activity_sums'] > 0\n",
        "\n",
        "Activity_df = df[activity_key]\n",
        "Hours_df = df[hours_key]\n",
        "##tilde used to invert key"
      ],
      "metadata": {
        "id": "vwOFN0F6nHhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Hours_df = Hours_df[[\"Entry Date\",\"User Name\", \"Activity Name\", \"Employee Title\",\"Hours\"]]\n",
        "\n",
        "Hours_df = Hours_df.groupby([\"Entry Date\",\"User Name\"]).agg({\n",
        "    \"Activity Name\": lambda x: ', '.join(set(x)),\n",
        "    \"Employee Title\": lambda x: ', '.join(set(x)),\n",
        "    \"Hours\": \"sum\"\n",
        "}).reset_index()\n",
        "\n",
        "# Convert 'Entry Date' in Hours_df to datetime64[ns]\n",
        "Hours_df[\"Entry Date\"] = pd.to_datetime(Hours_df[\"Entry Date\"])"
      ],
      "metadata": {
        "id": "hhX6yFbsnN3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns to check\n",
        "columns_to_check = ['VES DBQ + IMO total', 'LS DBQ + IMO total', 'QTC DBQ + IMO Total', 'Optum DBQ + IMO total', 'RHRP Eval total']\n",
        "\n",
        "# Convert act columns to ints\n",
        "Activity_df[columns_to_check] = Activity_df[columns_to_check].apply(pd.to_numeric, errors='coerce')\n",
        "Activity_df[columns_to_check] = Activity_df[columns_to_check].fillna(0)\n",
        "\n",
        "# Convert to int\n",
        "for col in columns_to_check:\n",
        "    Activity_df[col] = Activity_df[col].astype(int)"
      ],
      "metadata": {
        "id": "VjSDqJKiwn_H",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find the first non-null column name\n",
        "def find_non_zero_column(row):\n",
        "    cols = []\n",
        "    for col in columns_to_check:\n",
        "        if (row[col]) > 0:\n",
        "            cols.append(col)\n",
        "    return ', '.join(cols)\n",
        "\n",
        "# Function to find filled activity counts\n",
        "def find_non_zero_activity_number(row):\n",
        "    values = []\n",
        "    for col in columns_to_check:\n",
        "        if (row[col]) > 0:\n",
        "            values.append(str(row[col]))\n",
        "    return ', '.join(values)\n",
        "\n",
        "# Function to find filled activity sums\n",
        "def find_non_zero_activity_sums(row):\n",
        "    value = 0\n",
        "    for col in columns_to_check:\n",
        "        if (row[col]) > 0:\n",
        "            value += row[col]\n",
        "    return value\n",
        "\n",
        "# Apply the function to each row and create a new column\n",
        "Activity_df['VA_Company'] = Activity_df.apply(find_non_zero_column, axis=1)\n",
        "\n",
        "Activity_df['activity_count'] = Activity_df.apply(find_non_zero_activity_number, axis=1)\n",
        "\n",
        "Activity_df['activity_sums'] = Activity_df.apply(find_non_zero_activity_sums, axis=1)\n",
        "\n",
        "Activity_df_output = Activity_df.copy()"
      ],
      "metadata": {
        "id": "xugxgR5fXipX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove unneeded columns\n",
        "Activity_df =Activity_df[[\"Entry Date\",\"User Name\",\"Employee Title\",\"VA_Company\",\"activity_count\", \"activity_sums\"]]\n",
        "\n",
        "# Convert 'Entry Date' in Activity_df to datetime64[ns]\n",
        "Activity_df[\"Entry Date\"] = pd.to_datetime(df[\"Entry Date\"], dayfirst=False)"
      ],
      "metadata": {
        "id": "MD1Hanx3wzBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_df = pd.merge(Hours_df, Activity_df, on=[\"Entry Date\",\"User Name\",\"Employee Title\"], how=\"outer\")\n",
        "\n",
        "output_df['Hours'] = output_df['Hours'].fillna(0)\n",
        "output_df['activity_sums'] = output_df['activity_sums'].fillna(0)"
      ],
      "metadata": {
        "id": "xF1DE6_pz9yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create csv file with copmpleted output\n",
        "#output_df.to_csv('/content/drive/Shareddrives/Replicon Data Source/Data Sources/Cleaned_Salary_Report_Output.csv', index=False)"
      ],
      "metadata": {
        "id": "2-adUnYI0a8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill NA values with blank strings because sheets doesn't like that\n",
        "output_df = output_df.fillna('')\n",
        "\n",
        "# Convert 'Entry Date' to string format\n",
        "output_df['Entry Date'] = output_df['Entry Date'].dt.strftime(\"%-d-%b-%y\")\n",
        "\n",
        "\n",
        "#Open specified google sheets WB.Open sheet1.Clear the contents\n",
        "worksheet = gc.open('Cleaned_Salary_Report_Output').sheet1\n",
        "worksheet.clear()\n",
        "\n",
        "# Fill sheet with dataframe contents\n",
        "worksheet.update([output_df.columns.values.tolist()] + output_df.values.tolist(), raw=False)\n"
      ],
      "metadata": {
        "id": "GyGBsil0hjzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "669bf940-c202-40ac-c578-2ea1e03e9236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1cjNYSBarKxqE9ziKe0DsXpFkCv9EA56CIf_K5Ydh_pA',\n",
              " 'updatedRange': 'Cleaned_Salary_Report_Output!A1:H687',\n",
              " 'updatedRows': 687,\n",
              " 'updatedColumns': 8,\n",
              " 'updatedCells': 5496}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vkuRt7sFN3hd"
      }
    }
  ]
}